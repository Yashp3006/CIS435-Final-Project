# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15uKeb1W97hPrUDjymlo36Pv6TKajFf-O
"""

import pandas as pd
import numpy as np
from collections import Counter

def one_r(train_data, test_data, class_column):
    attributes = [col for col in train_data.columns if col != class_column]
    attribute_errors = {}
    attribute_rules = {}

    for attribute in attributes:
        rules = {}
        error_count = 0
        total_count = 0

        unique_values = train_data[attribute].unique()

        for value in unique_values:
            instances = train_data[train_data[attribute] == value]
            class_counts = instances[class_column].value_counts()

            if len(class_counts) > 0:
                most_frequent_class = class_counts.idxmax()
                rules[value] = most_frequent_class

                correct_predictions = instances[
                    instances[class_column] == most_frequent_class
                ].shape[0]
                total_instances = instances.shape[0]
                errors = total_instances - correct_predictions

                error_count += errors
                total_count += total_instances

        if total_count > 0:
            error_rate = error_count / total_count
            attribute_errors[attribute] = error_rate
            attribute_rules[attribute] = rules

    if attribute_errors:
        best_attribute = min(attribute_errors, key=attribute_errors.get)
        best_rules = attribute_rules[best_attribute]

        predictions = []
        for _, instance in test_data.iterrows():
            attribute_value = instance[best_attribute]

            if attribute_value in best_rules:
                prediction = best_rules[attribute_value]
            else:
                prediction = train_data[class_column].value_counts().idxmax()

            predictions.append(prediction)

        actual = test_data[class_column].tolist()
        correct = sum(1 for p, a in zip(predictions, actual) if p == a)
        accuracy = correct / len(actual) if len(actual) > 0 else 0

        return {
            "best_attribute": best_attribute,
            "rules": best_rules,
            "predictions": predictions,
            "accuracy": accuracy,
            "error_rate": attribute_errors[best_attribute],
        }

    return None

def load_data(file_path, header="infer", separator=" ", column_names=None):
    try:
        data = pd.read_csv(file_path, header=header, sep=separator, names=column_names)
        return data
    except Exception as e:
        print(f"âŒ Error loading data from {file_path}: {e}")
        return None

def print_1r_results(result):
    if result is None:
        print("âŒ No valid rules found.")
        return

    print(f"ğŸ” Best Attribute: {result['best_attribute']}")
    print(f"ğŸ“š Rules:")
    for value, predicted_class in result["rules"].items():
        print(f"  {result['best_attribute']} = {value} â†’ {predicted_class}")
    print(f"â— Error Rate: {result['error_rate'] * 100:.2f}%")
    print(f"âœ… Accuracy on Test Set: {result['accuracy'] * 100:.2f}%")

if __name__ == "__main__":
    train_file = "/content/mysterious_train.txt"  # Update path if using locally
    test_file = "/content/mysterious_test.txt"  # Update path if using locally
    column_names = ["attr1", "attr2", "attr3", "attr4", "class"]

    train_data = load_data(train_file, header=None, separator=" ", column_names=column_names)
    test_data = load_data(test_file, header=None, separator=" ", column_names=column_names)
    class_column = "class"

    if train_data is not None and test_data is not None:
        result = one_r(train_data, test_data, class_column)
        print_1r_results(result)